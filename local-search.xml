<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>pycharm连接服务器</title>
    <link href="/2025/01/07/pycharm%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <url>/2025/01/07/pycharm%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<font size=3><p>记一下pycharm连接远程服务器，步骤。</p><span id="more"></span><h2 id="一、建立远程服务器连接"><a href="#一、建立远程服务器连接" class="headerlink" title="一、建立远程服务器连接"></a>一、建立远程服务器连接</h2><h3 id="1-1-创建远程连接"><a href="#1-1-创建远程连接" class="headerlink" title="1.1 创建远程连接"></a>1.1 创建远程连接</h3><p><img src="https://s2.loli.net/2025/01/07/CpflgDc7yEtmsje.png" alt="image.png"></p><h3 id="1-2-本地-远程项目文件夹映射"><a href="#1-2-本地-远程项目文件夹映射" class="headerlink" title="1.2 本地-远程项目文件夹映射"></a>1.2 本地-远程项目文件夹映射</h3><p><img src="https://s2.loli.net/2025/01/07/INDzQwTGuBPcLdo.png" alt="image.png"></p><h3 id="1-3-验证连接是否成功-调出服务器文件目录"><a href="#1-3-验证连接是否成功-调出服务器文件目录" class="headerlink" title="1.3 验证连接是否成功(调出服务器文件目录)"></a>1.3 验证连接是否成功(调出服务器文件目录)</h3><p><img src="https://s2.loli.net/2025/01/07/15EgjS4FNiIJclZ.png" alt="image.png"></p><h2 id="二、在终端打开SSH连接"><a href="#二、在终端打开SSH连接" class="headerlink" title="二、在终端打开SSH连接"></a>二、在终端打开SSH连接</h2><p><img src="https://s2.loli.net/2025/01/07/rnsW9lGyZ6MKDIO.png" alt="image.png"></p><h2 id="三、新建虚拟环境"><a href="#三、新建虚拟环境" class="headerlink" title="三、新建虚拟环境"></a>三、新建虚拟环境</h2>    <div class="fold">      <div class="fold-title fold-info collapsed" data-toggle="collapse" href="#collapse-8f7bdefe" role="button" aria-expanded="false" aria-controls="collapse-8f7bdefe">        <div class="fold-arrow">▶</div>依据requirments安装依赖库      </div>      <div class="fold-collapse collapse" id="collapse-8f7bdefe">        <div class="fold-content">          <figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs vim">conda create --name dc_env <span class="hljs-keyword">python</span>=<span class="hljs-number">3.7</span><br><br><span class="hljs-keyword">cd</span> dc_code/<br><br><span class="hljs-keyword">ls</span> |<span class="hljs-keyword">grep</span> requirements.txt<br><br>conda activate dc_env<br><br>pip install -r requirements.txt -i https://mirrors.aliyun.<span class="hljs-keyword">com</span>/pypi/simple<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="四、本地配置python解释器"><a href="#四、本地配置python解释器" class="headerlink" title="四、本地配置python解释器"></a>四、本地配置python解释器</h2><h3 id="4-1-查询服务器某环境的python解释器路径"><a href="#4-1-查询服务器某环境的python解释器路径" class="headerlink" title="4.1 查询服务器某环境的python解释器路径"></a>4.1 查询服务器某环境的python解释器路径</h3><p><img src="https://s2.loli.net/2025/01/07/u3SUw16PA5rfiCO.png" alt="image.png"></p><h3 id="4-2-本地pycharm配置python解释器"><a href="#4-2-本地pycharm配置python解释器" class="headerlink" title="4.2 本地pycharm配置python解释器"></a>4.2 本地pycharm配置python解释器</h3><p><img src="https://s2.loli.net/2025/01/07/jTiUmEtyvZYqIC5.png" alt="image.png"></p><p><img src="https://s2.loli.net/2025/01/07/a4o8jtLOEnrVleq.png" alt="image.png"></p><p><img src="https://s2.loli.net/2025/01/07/W7Gxe5okwb6T4na.png" alt="image.png"></p><p>OK，环境配置完成，可以按照readme来测试代码了。</p><h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2><ul><li><a href="https://blog.csdn.net/qq_43755954/article/details/143301325">pip install -r requirements.txt下载速度慢</a></li><li><a href="https://www.cnblogs.com/nickchen121/p/11107842.html">Anaconda常用命令</a></li><li><a href="https://blog.csdn.net/qq_45100200/article/details/130355935?ops_request_misc=%257B%2522request%255Fid%2522%253A%25229b52b46ffddd03caa0ba8ef28f39735a%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=9b52b46ffddd03caa0ba8ef28f39735a&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-130355935-null-null.142%5Ev101%5Epc_search_result_base8&utm_term=pycharm%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8&spm=1018.2226.3001.4187">PyCharm连接远程服务器配置过程</a></li></ul></font>]]></content>
    
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>注意力机制</title>
    <link href="/2024/12/18/9-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
    <url>/2024/12/18/9-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<font size=3><p>学习注意力机制的原理和实现代码</p><span id="more"></span><h1 id="1-注意力机制"><a href="#1-注意力机制" class="headerlink" title="1.注意力机制"></a>1.注意力机制</h1><p>查询对象Query，被查询对象Value，通过去计算Q和V里的事物的<strong>相似度</strong>(更接近)，来判断哪些东西对Q来说更重要，哪些更不重要。</p><p>Q，$K &#x3D;k_1,k_2,\cdots,k_n$</p><p>通过点乘求内积的方法计算Q和K里的每一个事物的相似度，就可以拿到Q和$k_1$的相似度值$s_1$、Q和$k_2$的相似度值$s_2$、Q和$k_n$的相似度值$s_n$。计算$QK^T$后为避免输入的值差异过大导致Softmax的概率值过于极端，需要<strong>归一化</strong>，归一化的方式是<strong>除以嵌入向量维度的平方根。</strong></p><p>做一层$softmax(s_1, s_2,\cdots,s_n)$就可以得到概率$(a_1,a_2,\cdots,a_n)$，进而找到哪个事物对Q更重要。</p><p><img src="https://s2.loli.net/2024/12/18/ibh63dSvEWmJNG9.png" alt="image.png"></p><p>最后做一个汇总，拿到**经过注意力计算之后的图片$V’$**，现在这张图片中多了一些信息，多了于Q而言更重要、更不重要的信息。</p><p>$V&#x3D;(v_1, v_2, \cdots, v_n)$</p><p>$(a_1,a_2,\cdots,a_n) *+(v_1,v_2,\cdots,v_n)&#x3D;(a_1v_1+a_2v_2+\cdots+a_nv_n)$ &#x3D; V’</p><p><img src="https://s2.loli.net/2024/12/18/No5PiGVS4KZ2A9X.png" alt="image.png"></p><h1 id="2-自注意力机制-Self-attention"><a href="#2-自注意力机制-Self-attention" class="headerlink" title="2.自注意力机制(Self-attention)"></a>2.自注意力机制(Self-attention)</h1><p>在注意力机制中，一般来说Key和Value是相等的，或者一定具有某种关系。而Self-Attention中， Query、Key、Value三者是同源的，即K$\approx$V$\approx$Q，来源于同一个X。</p><p><strong>对X分别做三次线性变换，得到Query、Key、Value</strong>，通过X找到X里面的关键点。接下来的步骤和注意力机制一模一样，如图，列表示一个个X词向量，行表示分别要和句子中的每个词做一下相似度计算。</p><p>效果是：给定一个 X，通过自注意力模型，得到一个 Z，这个 Z 就是对 X 的新的表征（词向量），Z 这个词向量相比较 X 拥有了句法特征和语义特征。</p><p><img src="https://s2.loli.net/2024/12/18/mx1Rgsy7Sw9PAk2.png" alt="image.png"><br><img src="https://s2.loli.net/2024/12/18/UpFLilbYhmyWZXg.png" alt="image.png"></p><h1 id="3-多头自注意力-Multi-Head-Self-Attention"><a href="#3-多头自注意力-Multi-Head-Self-Attention" class="headerlink" title="3.多头自注意力(Multi-Head Self-Attention)"></a>3.多头自注意力(Multi-Head Self-Attention)</h1><h2 id="3-1-什么是多头"><a href="#3-1-什么是多头" class="headerlink" title="3.1 什么是多头"></a>3.1 什么是多头</h2><p>对于X,我们不是说，直接拿 X 去得到 Z，而是把 X 分成了 8 块（8 头），得到 Z0-Z7，然后把 Z0-Z7 拼接起来，再做一次线性变换（改变维度）得到 Z，使其和原来的X词向量维度一致。</p><h2 id="3-2-有什么作用"><a href="#3-2-有什么作用" class="headerlink" title="3.2 有什么作用"></a>3.2 有什么作用</h2><p>把X切成8个，这样原先在一个位置的X，去了空间上的8个位置，通过对8个点进行寻找(非线性变换，映射到更合理的空间)，找到更合适的位置。</p><p><img src="https://s2.loli.net/2024/12/18/f5kVD6dHu2UhzSn.png" alt="image.png"></p>]]></content>
    
    
    <categories>
      
      <category>metric-learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Attention mechanism</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>度量学习思路整合</title>
    <link href="/2024/12/09/8-%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0%E6%96%87%E7%8C%AE%E8%B0%83%E7%A0%94%E8%AE%B0%E5%BD%95/"/>
    <url>/2024/12/09/8-%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0%E6%96%87%E7%8C%AE%E8%B0%83%E7%A0%94%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<font size=3><p>few-shot learning的度量学习方法阅读与总结，目标是找到一篇文章，解决few-shot的以下问题：<br>在基类上，模型学会区分相似和不相似的实例，从而提高下游任务的性能；<br>支持集的样本过少，计算得到的类代表原型和实际期望得到的类原型有较大偏差，如何矫正<strong>有偏的类原型</strong>，进而提高模型分类精度。</p><span id="more"></span><h2 id="1-Prototype-Rectification-for-Few-Shot-Learning"><a href="#1-Prototype-Rectification-for-Few-Shot-Learning" class="headerlink" title="1.Prototype Rectification for Few-Shot Learning"></a>1.Prototype Rectification for Few-Shot Learning</h2><h3 id="1-1-基本信息"><a href="#1-1-基本信息" class="headerlink" title="1.1 基本信息"></a>1.1 基本信息</h3><ul><li><p>2020年，ECCV会议论文</p></li><li><p>无开源源码</p></li><li><p>提出了如何减少类原型的偏置、减少support和query dataset之间的分布差。</p></li></ul><h3 id="1-2-方法记录"><a href="#1-2-方法记录" class="headerlink" title="1.2 方法记录"></a>1.2 方法记录</h3><h4 id="1-2-1-intra-class-bias"><a href="#1-2-1-intra-class-bias" class="headerlink" title="1.2.1 intra-class bias"></a>1.2.1 intra-class bias</h4><p>为了减少实际计算出的原型和真实原型之间的差距，采用<strong>伪标签策略</strong>，补充<code>support set</code>的样本，由此得到更接近真实的原型。具体操作是取<code>top-k</code>个置信度的未标记样本，加上伪标签，加入<code>support set</code>一起计算类代表原型，其中为了避免伪标签错分给原型带来大的误差，使用<strong>加权和的平均作为修改的原型</strong>，权重的计算公式：样本和basic prototypes有更大的余弦相似度，则在修改的原型中有更高占比。</p><div class="note note-info">            <p>伪标签有一个使用前提，即需要一次性给出某个类的所有未标记样本，不适用于一个个给测试样本的情况。<br>在脑电身份识别上，一个人作为一个类，<strong>他的测试样本是否可以一次性获取到？</strong>，决定了伪标签是否适用。</p>          </div><h4 id="1-2-2-cross-class-bias"><a href="#1-2-2-cross-class-bias" class="headerlink" title="1.2.2 cross-class bias"></a>1.2.2 cross-class bias</h4><p>首先两个set被假设为分布在同一个domain中，但<code>support set</code>和<code>quary set</code>之间存在<strong>分布差</strong>，提出为了减少两者的分布差，可以把<code>quary set</code>朝<code>support set</code>移动。具体地，文章提出给每个标准化后的quary feature$\overline{X_q}$添加一个转换参数epilon。<br><img src="https://s2.loli.net/2024/12/09/qnV2rhwZTyjYGM8.png" alt="image.png"></p><div class="note note-info">            <p>减小分布差，脑电身份识别，support set用的是登记session的样本，quary set可能用的是另一个session的样本，由于时变性，两者的分布差肯定是存在的，甚至于同一个session，随着人状态的波动，样本之间估计也存在明显的分布差，这个方法可以一试。</p>          </div><h2 id="2-Free-Lunch-for-Few-shot-Learning-Distribution-Calibration"><a href="#2-Free-Lunch-for-Few-shot-Learning-Distribution-Calibration" class="headerlink" title="2.Free Lunch for Few-shot Learning: Distribution Calibration"></a>2.Free Lunch for Few-shot Learning: Distribution Calibration</h2><h3 id="2-1-基本信息"><a href="#2-1-基本信息" class="headerlink" title="2.1 基本信息"></a>2.1 基本信息</h3><ul><li><p>2021年，ICLR会议论文</p></li><li><p>源码：<a href="https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration">Few_Shot_Distribution_Calibration</a></p></li><li><p>提出从语义相似的基类(s)迁移统计数据来校准这些少数样本类的分布，接着<strong>依据新分布的均值和方差随机采样一定数量的样本</strong>，对novel classes的n_way k_shot任务的支持集进行补充，补充后的support set aug输入分类器fit。</p></li></ul><h3 id="2-2-方法记录"><a href="#2-2-方法记录" class="headerlink" title="2.2 方法记录"></a>2.2 方法记录</h3><p>前提假设：假设特征嵌入的每个维度都服从<strong>高斯分布</strong>。</p><p>这篇代码<strong>基类</strong>是有充足样本的类，用别人的SOTA分类模型，取倒数第二层作为特征提取器，用于提取基类和novel类的特征嵌入。接着计算每个基类特征层面的均值向量和协方差。</p><p>测试类(novel classes)用的是轮次训练的方式，例如：</p>    <div class="fold">      <div class="fold-title fold-info collapsed" data-toggle="collapse" href="#collapse-8f7bdefe" role="button" aria-expanded="false" aria-controls="collapse-8f7bdefe">        <div class="fold-arrow">▶</div>FSLTask参数      </div>      <div class="fold-collapse collapse" id="collapse-8f7bdefe">        <div class="fold-content">          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs PYTHON"><span class="hljs-comment"># ---- data loading</span><br>    dataset = <span class="hljs-string">&#x27;miniImagenet&#x27;</span><br>    n_shot = <span class="hljs-number">1</span><br>    n_ways = <span class="hljs-number">5</span><br>    n_queries = <span class="hljs-number">15</span><br>    n_runs = <span class="hljs-number">10000</span><br>    n_lsamples = n_ways * n_shot<br>    n_usamples = n_ways * n_queries<br>    n_samples = n_lsamples + n_usamples<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><p>每次从novel classes中抽5个类，每个类有1个support sample，15个query sample。每一次run，对抽取的5个support_data(先转成特征嵌入)分别做分布校准，然后生成若干个数的特征向量作为support集的<strong>补充</strong>，一起输入分类器fit，在query samples上测试，计算acc，最后取10000次run的平均acc。</p><p>分布校准core代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs PYTHON"><span class="hljs-keyword">def</span> <span class="hljs-title function_">distribution_calibration</span>(<span class="hljs-params">query, base_means, base_cov, k,alpha=<span class="hljs-number">0.21</span></span>):<br>    dist = []  <span class="hljs-comment"># 计算support sample(变量名叫query)和mean之间的欧式距离</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(base_means)):<br>        dist.append(np.linalg.norm(query-base_means[i]))<br>    index = np.argpartition(dist, k)[:k]  <span class="hljs-comment"># 从数组 dist 中找到前𝑘小的元素的索引</span><br>    mean = np.concatenate([np.array(base_means)[index], query[np.newaxis, :]])<br>    calibrated_mean = np.mean(mean, axis=<span class="hljs-number">0</span>)<br>    calibrated_cov = np.mean(np.array(base_cov)[index], axis=<span class="hljs-number">0</span>)+alpha<br><br>    <span class="hljs-keyword">return</span> calibrated_mean, calibrated_cov<br></code></pre></td></tr></table></figure><div class="note note-primary">            <ol><li>这篇文章在<strong>细粒度数据集CUB</strong>上也应用了DC方法，有超过200种不同的鸟类图片。每个人的脑电虽然说各自有判别性特征，其实还是很相似的细粒度数据，这个方法通过迁移<span class="label label-secondary">k</span>个距离最小的基类的分布，来直接增加支持集的样本，进而提高分类性能。</li><li>要调的超参数多，采样个数、k个基类、离散程度a。</li><li>在脑电上是否有效呢？特征向量都是经过标准化&#x2F;幂变换的。</li></ol>          </div><h2 id="3-Semantic-Based-Implicit-Feature-Transform-for-Few-Shot-Classification"><a href="#3-Semantic-Based-Implicit-Feature-Transform-for-Few-Shot-Classification" class="headerlink" title="3.Semantic-Based Implicit Feature Transform for Few-Shot Classification"></a>3.Semantic-Based Implicit Feature Transform for Few-Shot Classification</h2><h3 id="3-1-基本信息"><a href="#3-1-基本信息" class="headerlink" title="3.1 基本信息"></a>3.1 基本信息</h3><ul><li><p>2024年，International Journal of Computer Vision</p></li><li><p>源码：<a href="https://github.com/pmhDL/SIFT.git">SIFT</a></p></li><li><p>借鉴的是前面分布矫正的论文，同样是通过从基类补充特征向量到novel类上面去，不同的是图像类别标签（如cat、dog），<strong>本身具有语义信息</strong>，可以用不同的词向量来表达。然后通过语义嵌入的相似度来选择最近的基类，而不是前面通过统计特征。</p></li></ul><h3 id="3-2-方法记录"><a href="#3-2-方法记录" class="headerlink" title="3.2 方法记录"></a>3.2 方法记录</h3><ul><li><p>脑电的类别标签纯粹是<span class="label label-secondary">'Person A'</span>、<span class="label label-secondary">'Person B'</span>的形式，并不具有语义信息，所以如果要用，应该采用Free Lunch的方法<strong>做跨时段的分布矫正</strong>。</p></li><li><p>提出了一种原型矫正的方法。适用于transductive setting，即查询样本全部一次给出的情况。通过K-means把查询样本分簇为N类，接着建立路径规划问题的数学模型，为这N个类别确定互相不重复的标签，与初始的每个类原型做平均。</p></li></ul>    <div class="fold">      <div class="fold-title fold-info collapsed" data-toggle="collapse" href="#collapse-6ae3e036" role="button" aria-expanded="false" aria-controls="collapse-6ae3e036">        <div class="fold-arrow">▶</div>原型矫正实现      </div>      <div class="fold-collapse collapse" id="collapse-6ae3e036">        <div class="fold-content">          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs PYTHON"><span class="hljs-keyword">def</span> <span class="hljs-title function_">updateproto</span>(<span class="hljs-params">Xs, ys, cls_center, way</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新原型 (prototype)，并与聚类中心 (cluster center) 结合&quot;&quot;&quot;</span><br>    <br>    <span class="hljs-comment"># 调用 np_proto 计算每个类别的原型</span><br>    proto = np_proto(Xs, ys, way)  <br>    <br>    <span class="hljs-comment"># 计算每个类别原型与所有聚类中心之间的平方欧式距离</span><br>    <span class="hljs-comment"># 使用广播机制，扩展 proto 和 cls_center 的维度后相减</span><br>    dist = ((proto[:, np.newaxis, :] - cls_center[np.newaxis, :, :]) ** <span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>(<span class="hljs-number">2</span>)  <br>    <br>    <span class="hljs-comment"># 找到每个类别原型距离最近的聚类中心索引</span><br>    <span class="hljs-built_in">id</span> = dist.argmin(<span class="hljs-number">1</span>)  <br>    feat_proto = np.zeros((way, Xs.shape[<span class="hljs-number">1</span>]))  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(way):<br>        <span class="hljs-comment"># 将当前类别的原型和其最近的聚类中心取平均值</span><br>        feat_proto[i] = (cls_center[<span class="hljs-built_in">id</span>[i]] + proto[i]) / <span class="hljs-number">2</span>  <br>    <br>    <span class="hljs-keyword">return</span> feat_proto  <br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="4-Matching-Feature-Sets-for-Few-Shot-Image-Classification"><a href="#4-Matching-Feature-Sets-for-Few-Shot-Image-Classification" class="headerlink" title="4.Matching Feature Sets for Few-Shot Image Classification"></a>4.Matching Feature Sets for Few-Shot Image Classification</h2><h3 id="4-1-基本信息"><a href="#4-1-基本信息" class="headerlink" title="4.1 基本信息"></a>4.1 基本信息</h3><ul><li><p>2022年，CVPR会议论文</p></li><li><p>源码：<a href="https://lvsn.github.io/SetFeat/">SetFeat-fs</a></p></li><li><p>以Conv4-64骨干网络为例，提出把一张图像输入进去，经过一个Block，就输出一个经<strong>自注意力机制mapper</strong>计算后的特征向量$h_m$，这样处理从一张图片中提取出一组m(4)个特征向量。距离度量用的是负余弦相似度，实际上和原型网络的距离度量很相似，区分在于有多个特征向量，它这里<strong>统一了向量的shape</strong>，相当于在同一个特征空间内，按mapper聚合多个类中心。</p></li></ul><h3 id="4-2-方法记录"><a href="#4-2-方法记录" class="headerlink" title="4.2 方法记录"></a>4.2 方法记录</h3><ul><li><p>如何利用多个不同层提取出的特征向量，核心如下公式所示。<br><img src="https://s2.loli.net/2025/01/09/NMQJKOybilHTAGV.png" alt="image.png"></p></li><li><p><strong>训练流程：</strong>两个阶段，<span class="label label-primary">第一阶段</span>就是正常带FC层的分类器，并且本文是在每个Block后面都接一个FC层，分别训练到这个Block为止的网络，<span class="label label-primary">第二阶段</span>，舍去FC层，应用轮次训练在基类上模拟FSL Task，通过公式6的负对数概率计算loss，反向传播微调编码器的参数。微调结束，最终在novel类上面推理，之前的Free Lunch也是一样的流程。<br><img src="https://s2.loli.net/2025/01/09/eOXMZnHkxYScaRP.png" alt="image.png"></p></li></ul><div class="note note-secondary">            <ol><li>总结一下，它提高原型网络分类精度的手段就是，同一个特征space，一个类别聚合m个类中心。</li><li>感觉第一阶段训练就相当于独立地训练了4个encoder，但是又不独立，前面的参数是要重复使用的，具体要看代码train部分。</li></ol>          </div><div class="note note-info">            <ol><li>这种在预训练阶段，训练一个分类器的做法和我之前看的<strong>有监督对比学习</strong>训练编码器的方式不一样，我的想法是也许可以借用这个metric，然后用SCL的做法分别独立训练出3个encoder。之后可以有两种metric方法，一种是和本文做法一样，投射到同一个特征空间；另一种映射到不同特征空间分别做相似度计算，再求和，作为新的metric。</li><li>还有一个想法是SCL的<strong>encoder很关键，</strong>决定了特征向量的质量，借鉴GoogleNet的多尺度卷积方法，预训练出一个encoder，也可以试一下。</li></ol>          </div><h3 id="4-3-参考博客"><a href="#4-3-参考博客" class="headerlink" title="4.3 参考博客"></a>4.3 参考博客</h3><ul><li><p><a href="https://blog.csdn.net/weixin_43499457/article/details/124595010?ops_request_misc=%257B%2522request%255Fid%2522%253A%25223c42cb44ac6d1d4ee40531845d5a092b%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=3c42cb44ac6d1d4ee40531845d5a092b&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-124595010-null-null.142%5Ev101%5Epc_search_result_base8&utm_term=%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0&spm=1018.2226.3001.4187">有监督对比学习在分类任务中的应用 Supervised Contrastive Learning</a></p></li><li><p><a href="https://blog.csdn.net/c___c18/article/details/144056112?ops_request_misc=&request_id=&biz_id=102&utm_term=%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-144056112.142%5Ev101%5Epc_search_result_base8&spm=1018.2226.3001.4187">监督对比学习代码实现与分析（Supervised Contrastive Learning in NLP）</a></p></li><li><p><a href="https://blog.csdn.net/Bluebro/article/details/130035707">主干网络backbone讲解—— Conv4与Resnet12</a></p></li></ul><h2 id="5-BSNet-Bi-Similarity-Network-for-Few-shot-Fine-grained-Image-Classification"><a href="#5-BSNet-Bi-Similarity-Network-for-Few-shot-Fine-grained-Image-Classification" class="headerlink" title="5.BSNet: Bi-Similarity Network for Few-shot  Fine-grained Image Classification"></a>5.BSNet: Bi-Similarity Network for Few-shot  Fine-grained Image Classification</h2><h3 id="5-1-基本信息"><a href="#5-1-基本信息" class="headerlink" title="5.1 基本信息"></a>5.1 基本信息</h3><ul><li><p>2020年，‌IEEE Transactions on Image Processing（TIP）期刊论文</p></li><li><p>源码：<a href="https://github.com/PRIS-CV/BSNet">BSNet</a></p></li><li><p>代码格式简洁，是基于度量学习的图像细粒度分类，提出同时使用余弦相似度和欧式距离两种loss，即在ProtoNet上添加一个余弦相似度的loss，分类精度在图像分类上有所提高。</p></li></ul><div class="note note-light">            <p>最后调优模型的时候可以试一下，有空看看代码。</p>          </div> <h2 id="6-Supervised-Contrastive-Learning"><a href="#6-Supervised-Contrastive-Learning" class="headerlink" title="6.Supervised Contrastive Learning"></a>6.Supervised Contrastive Learning</h2><h3 id="6-1-基本信息"><a href="#6-1-基本信息" class="headerlink" title="6.1 基本信息"></a>6.1 基本信息</h3><ul><li><p>2020年，NeurIPS</p></li><li><p>源码：<a href="https://github.com/HobbitLong/SupContrast">SupContrast</a></p></li><li><p>提出….</p></li></ul></font>]]></content>
    
    
    <categories>
      
      <category>metric-learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>paper</tag>
      
      <tag>metric-learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PowerPoint修炼</title>
    <link href="/2024/12/07/7.ppt%E6%8A%80%E5%B7%A7%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/12/07/7.ppt%E6%8A%80%E5%B7%A7%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<font size=3><h1 id="1-PPT整体展示图表之后局部高亮"><a href="#1-PPT整体展示图表之后局部高亮" class="headerlink" title="1.PPT整体展示图表之后局部高亮"></a>1.PPT整体展示图表之后局部高亮</h1><p><a href="https://www.bilibili.com/video/BV13r4y1c7r1/?vd_source=a9e78e47d3e6d67d875c0260caff8550">步骤教学</a></p><p><img src="https://s2.loli.net/2024/12/07/KUh4etcvqSk2BDd.gif" alt="ppt.gif"></p><h1 id="2-Others"><a href="#2-Others" class="headerlink" title="2.Others"></a>2.Others</h1><ul><li><a href="https://www.freeconvert.com/zh/convert/video-to-gif">视频转GIF工具</a></li><li><a href="https://blog.csdn.net/weixin_38314865/article/details/104440652">PPT立方体形状变薄</a></li></ul></font>]]></content>
    
    
    
    <tags>
      
      <tag>PPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>评估指标记录</title>
    <link href="/2024/12/05/6.%E5%88%86%E7%B1%BB%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/"/>
    <url>/2024/12/05/6.%E5%88%86%E7%B1%BB%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</url>
    
    <content type="html"><![CDATA[<font size=3><p>电子笔记</p><span id="more"></span><h1 id="1-AUC-are-under-curve"><a href="#1-AUC-are-under-curve" class="headerlink" title="1.AUC(are under curve)"></a>1.AUC(are under curve)</h1><h2 id="1-1什么是AUC"><a href="#1-1什么是AUC" class="headerlink" title="1.1什么是AUC"></a>1.1什么是AUC</h2><p>用于评估分类器的分类效果，对于真实类别为1的样本，分类器预测为1的概率(即TPrate)要大于真实类别为0而预测类别为1的概率(即FPrate)，即AUC&gt;0.5。</p><h2 id="1-2如何计算AUC"><a href="#1-2如何计算AUC" class="headerlink" title="1.2如何计算AUC"></a>1.2如何计算AUC</h2><p>在有M个正样本,N个负样本的数据集里。一共有M*N对样本（一对样本即一个正样本与一个负样本）。统计这M*N对样本里，正样本的预测概率大于负样本的预测概率的个数。<br><img src="https://s2.loli.net/2024/12/09/lj6xh4XCm7oqgDu.png" alt="image.png"></p><h2 id="1-3接口参数含义"><a href="#1-3接口参数含义" class="headerlink" title="1.3接口参数含义"></a>1.3接口参数含义</h2><p><code>roc_auc_score(test_labels, probs, multi_class=&#39;ovr&#39;)</code></p><div class="note note-info">            <ol><li>test_labels: 实际的类别标签，shape是 [N,]</li><li>probs: 每个样本在各个类别上的概率，shape是[N, C]</li><li>指定计算多类别问题的 AUC (<strong>One-vs-Rest 策略</strong>)</li></ol>          </div><h1 id="2-AccuracyCalculator使用"><a href="#2-AccuracyCalculator使用" class="headerlink" title="2.AccuracyCalculator使用"></a>2.AccuracyCalculator使用</h1><p>在<strong>pytorch-metric-learning</strong>中，AccuracyCalculator主要用于计算准确率（如 top-k 准确率）。通过嵌入向量之间的相似度来推测每个样本的类别，并与真实标签进行比较，相同则预测正确。这种方法是基于<strong>最近邻</strong>来判断类别，预测准确率的。</p><p>使用方法：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">from</span> pytorch_metric_learning <span class="hljs-keyword">import</span> losses<br><span class="hljs-keyword">from</span> pytorch_metric_learning.utils.accuracy_calculator <span class="hljs-keyword">import</span> AccuracyCalculator<br><br><span class="hljs-comment"># 初始化 AccuracyCalculator: 参数k值，指定 top-k 精度</span><br>accuracy_calculator = AccuracyCalculator(k=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 计算准确率</span><br>accuracy = accuracy_calculator.calculate(<br>    embeddings=embeddings,  <span class="hljs-comment"># 模型输出的嵌入向量 [batch_size, embedding_dim]</span><br>    labels=labels,          <span class="hljs-comment"># 标签 [batch_size]</span><br>)<br></code></pre></td></tr></table></figure><h1 id="3-资料"><a href="#3-资料" class="headerlink" title="3.资料"></a>3.资料</h1><ul><li><a href="https://www.zhihu.com/question/39840928?from=profile_question_card">AUC如何理解？</a></li><li><a href="https://blog.csdn.net/qq_22238533/article/details/78666436">AUC的计算方法</a></li></ul></font>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>sklearn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ear-EEG数据集调研</title>
    <link href="/2024/11/27/5.Ear-EEG%E6%95%B0%E6%8D%AE%E9%9B%86%E8%B0%83%E7%A0%94/"/>
    <url>/2024/11/27/5.Ear-EEG%E6%95%B0%E6%8D%AE%E9%9B%86%E8%B0%83%E7%A0%94/</url>
    
    <content type="html"><![CDATA[<font size=3><p>有关<strong>耳脑电</strong>的概述、4个应用类别的可行性、公开数据集的材料调研。</p><span id="more"></span><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h1><p>和全头皮脑电类似，ear-EEG同样是通过在皮肤上放置电极记录微小的电压变化，以测量动态的大脑活动。电极传感器可以放置在外耳的不同位置（耳廓、耳甲、耳道），检测设备材料种类很多，测量方式也分干&#x2F;湿电极，但是<strong>与头皮脑电相比，耳脑电的电极部署数量少，且信号幅度(signal amplitude)明显低于头皮脑电</strong>10-20dB。</p><p>耳脑电靠近<strong>颞叶(Temporal Lobe)区域</strong>，这个区域和听觉、语言处理、记忆和情感都相关，在事件相关电位(ERPs)、脑机接口(BCI)、睡眠、癫痫4个领域都已有研究来证明耳脑电信号的可行性。</p><h1 id="2-应用领域"><a href="#2-应用领域" class="headerlink" title="2.应用领域"></a>2.应用领域</h1><h2 id="2-1-事件相关电位"><a href="#2-1-事件相关电位" class="headerlink" title="2.1 事件相关电位"></a>2.1 事件相关电位</h2><p>ERP是测量的大脑对视觉、声音或触觉的短暂刺激的反应。耳脑电被证明可可靠测量几个熟知的ERPs，耳脑电实现的EEG诱发范式大多数与听觉刺激有关，包括<strong>听觉诱发电位</strong>(auditory-evoked potentials，AEPs)和<strong>听觉稳态电位</strong>(multiple auditory-steady responses, ASSR)，以及<strong>SSVEP</strong>。</p><h2 id="2-2-脑机接口"><a href="#2-2-脑机接口" class="headerlink" title="2.2 脑机接口"></a>2.2 脑机接口</h2><p>BCIs是用于解码电生理信号去控制一个外部设备的技术。综述中介绍了多篇paper采集耳脑电然后用于注意力状态鉴别、驾驶员嗜睡分类。</p><h2 id="2-3-睡眠"><a href="#2-3-睡眠" class="headerlink" title="2.3 睡眠"></a>2.3 睡眠</h2><p>耳脑电适合于长期的监测睡眠质量，耳内传感器获取的数据可以被用于睡眠分期的评估，但也提到耳脑电的<strong>amplitude</strong>比标准EEG低。</p><h2 id="2-4-癫痫"><a href="#2-4-癫痫" class="headerlink" title="2.4 癫痫"></a>2.4 癫痫</h2><p>适合长期监测，指出耳脑电适合记录颞叶癫痫信号，并用于癫痫评估。</p><h1 id="3-公开数据集"><a href="#3-公开数据集" class="headerlink" title="3.公开数据集"></a>3.公开数据集</h1><h2 id="3-1-睡眠监测"><a href="#3-1-睡眠监测" class="headerlink" title="3.1 睡眠监测"></a>3.1 睡眠监测</h2><ul><li><a href="https://openneuro.org/datasets/ds004348/versions/1.0.5">Ear-EEG Sleep Monitoring 2017 (EESM17)</a></li></ul><p>睡眠监测数据集，包含9名受试者的夜间脑电图记录。这些recording包括<strong>脑电图、眼电图和下巴肌电图，以及 14 个耳部脑电图电极</strong>。</p><p>label分为两类，1:wake; 2:sleep</p><h2 id="3-2-运动想象"><a href="#3-2-运动想象" class="headerlink" title="3.2 运动想象"></a>3.2 运动想象</h2><ul><li><a href="https://ieee-dataport.org/open-access/ear-eeg-recording-brain-computer-interface-motor-task">Ear-EEG Recording for Brain Computer Interface of Motor Task</a></li></ul><p>左&#x2F;右手抓握运动想象数据集，包括6个受试者。耳部脑电图与头皮脑电图同时记录。8个耳电极放置在前耳道和后耳道（标记为 xF、xB）<br>以及耳甲的两个上部和下部位置（标记为 xOU 和 xOD）。所有耳部和头皮电极均以头皮REF电极为参考。<br>头皮GRD电极用作接地参考。以1000 Hz采样信号，然后用0.5 Hz至100 Hz之间的带通滤波器和陷波滤波器进行滤波。</p><h2 id="3-3-SSVEP"><a href="#3-3-SSVEP" class="headerlink" title="3.3 SSVEP"></a>3.3 SSVEP</h2><ul><li><a href="http://deepbci.korea.ac.kr/opensource/opendb/">EEG Dataset for SSVEP using Ear-EEG and Scalp-EEG</a></li></ul><p>数据集是韩国的一个网站，需要申请：<br><img src="https://s2.loli.net/2024/11/28/XMAbZFmxgo6rzfL.png" alt="image.png"></p><ul><li><a href="https://ieeexplore.ieee.org/abstract/document/8758838">论文_包含实验范式</a></li></ul><h3 id="3-3-1-论文摘要"><a href="#3-3-1-论文摘要" class="headerlink" title="3.3.1 论文摘要"></a>3.3.1 论文摘要</h3><p>耳-脑电对电极位置有自然的限制(例如，限制在耳内或耳周围)，无法充分获取信息丰富的大脑信号。在特定的BCI范式中，不利用<strong>耳周围颞叶的脑信号</strong>，实现可靠的耳-脑电性能是困难的。<br>例如，<strong>稳态视觉诱发电位(SSVEPs)主要产生于枕区，在耳-脑电中具有明显的衰减和扭曲幅度。</strong>因此，保持高水平的解码精度对于基于耳-脑电的SSVEP BCI是具有挑战性和必要的。<br>本文首先研究了在SSVEP范式下，利用枕区估计的目标脑电信号，采用线性和非线性回归方法来提高耳-脑电解码精度。…</p><h3 id="3-3-2-实验范式"><a href="#3-3-2-实验范式" class="headerlink" title="3.3.2 实验范式"></a>3.3.2 实验范式</h3><p>实验一共3个session，前两个session同时记录头皮脑电和耳脑电，第3个session只记录耳脑电。刺激频率有3种，一次trial范式如图所示。<br><img src="https://s2.loli.net/2024/11/28/EtQj2Y6CcBbxryN.png" alt="image.png"></p><p>11个subjects，采样频率500hz，0.3-50 Hz的带通滤波器和60Hz陷波滤波器。</p><ul><li>session1 和 session2，每类刺激50个trial，一共150trial。</li><li>session3，只获取耳-脑电图信号，每个类20个trial，一共60个trial。</li><li>三个session是不在<strong>不同的天</strong>获得的。</li></ul><p><img src="https://s2.loli.net/2024/11/28/hEjdCFwfsqXQLW5.png" alt="image.png"></p><h1 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4.参考资料"></a>4.参考资料</h1><ul><li><a href="https://en.wikipedia.org/wiki/Ear-EEG#History">Ear-EEG_wikipedia</a></li><li><a href="http://deepbci.korea.ac.kr/wp-content/uploads/2019/05/Discription.pdf">韩国ssvep数据集的范式说明</a></li><li>Ear-EEG Devices for the Assessment of Brain  Activity: A Review</li></ul></font>]]></content>
    
    
    
    <tags>
      
      <tag>ear-EEG</tag>
      
      <tag>database</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>面向对象实现文件下载系统</title>
    <link href="/2024/08/23/4-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E7%B3%BB%E7%BB%9F/"/>
    <url>/2024/08/23/4-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<p>Server端代码</p><span id="more"></span><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment">#!/usr/bin/python3</span><br><span class="hljs-comment"># @Time    : 2024/8/24 9:46</span><br><span class="hljs-comment"># @Author  : Proton</span><br><span class="hljs-comment"># @FileName: netdisk_server.py</span><br><span class="hljs-keyword">from</span> socket <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">import</span> struct<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Server</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, ip, port</span>):<br>        self.s_listen:socket = <span class="hljs-literal">None</span><br>        self.ip = ip<br>        self.port = port<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">tcp_init</span>(<span class="hljs-params">self</span>):<br>        self.s_listen = socket(AF_INET, SOCK_STREAM)<br>        self.s_listen.bind((self.ip, self.port))<br>        self.s_listen.listen(<span class="hljs-number">128</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">self</span>):<br>        new_client, client_addr = self.s_listen.accept()<br>        <span class="hljs-built_in">print</span>(client_addr)<br>        user = User(new_client)<br>        user.deal_command()<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    每一个user对象对应一个客户端</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, new_client</span>):<br>        self.user: socket = new_client<br>        self.username = <span class="hljs-literal">None</span><br>        self.path = os.getcwd()  <span class="hljs-comment"># 存储连上的用户的路径</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_send</span>(<span class="hljs-params">self, content_bytes</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        以开火车的形式发送，先发长度，再发内容</span><br><span class="hljs-string">        :param content:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        content_len_bytes = struct.pack(<span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-built_in">len</span>(content_bytes))<br>        self.user.send(content_len_bytes+content_bytes)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_recv</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        开火车接收，先接收文件名/内容长度，4B，再接收文件名/内容</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        train_head_bytes = self.user.recv(<span class="hljs-number">4</span>)<br>        train_head_len = struct.unpack(<span class="hljs-string">&#x27;I&#x27;</span>, train_head_bytes)<br>        <span class="hljs-comment"># 为什么不decode，因为不一定是文本，也可能是音乐or电影</span><br>        <span class="hljs-keyword">return</span> self.user.recv(train_head_len[<span class="hljs-number">0</span>])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">deal_command</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            <span class="hljs-comment"># 接收命令应该以开火车的形式收</span><br>            command = self.train_recv().decode(<span class="hljs-string">&#x27;utf8&#x27;</span>)<br>            <span class="hljs-keyword">if</span> command[:<span class="hljs-number">2</span>] == <span class="hljs-string">&#x27;ls&#x27;</span>:<br>                self.do_ls()<br>            <span class="hljs-keyword">elif</span> command[:<span class="hljs-number">2</span>] == <span class="hljs-string">&#x27;cd&#x27;</span>:<br>                self.do_cd(command)<br>            <span class="hljs-keyword">elif</span> command[:<span class="hljs-number">3</span>] == <span class="hljs-string">&#x27;pwd&#x27;</span>:<br>                self.do_pwd()<br>            <span class="hljs-keyword">elif</span> command[:<span class="hljs-number">2</span>] == <span class="hljs-string">&#x27;rm&#x27;</span>:<br>                self.do_rm(command)<br>            <span class="hljs-keyword">elif</span> command[:<span class="hljs-number">4</span>] == <span class="hljs-string">&#x27;puts&#x27;</span>:<br>                self.puts_file()<br>            <span class="hljs-keyword">elif</span> command[:<span class="hljs-number">4</span>] == <span class="hljs-string">&#x27;gets&#x27;</span>:<br>                self.gets_file(command)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;wrong command.&#x27;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">do_ls</span>(<span class="hljs-params">self</span>):<br>        data = <span class="hljs-string">&#x27;&#x27;</span><br>        cur_list = os.listdir(<span class="hljs-string">&#x27;.&#x27;</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> cur_list:<br>            data += i + <span class="hljs-string">&#x27; &#x27;</span>*<span class="hljs-number">5</span> + <span class="hljs-built_in">str</span>(os.stat(i).st_size) + <span class="hljs-string">&#x27;\n&#x27;</span><br>        self.train_send(data.encode(<span class="hljs-string">&#x27;utf8&#x27;</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">do_cd</span>(<span class="hljs-params">self, command</span>):<br>        path = command.split()[<span class="hljs-number">1</span>]<br>        os.chdir(path)<br>        self.path = os.getcwd()<br>        self.train_send(self.path.encode(<span class="hljs-string">&#x27;utf8&#x27;</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">do_pwd</span>(<span class="hljs-params">self</span>):<br>        self.train_send(self.path.encode(<span class="hljs-string">&#x27;utf8&#x27;</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">do_rm</span>(<span class="hljs-params">self, command</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        深度优先遍历，实现删除非空文件夹</span><br><span class="hljs-string">        :param command:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        rm_target = command.split()[<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">if</span> os.path.isdir(rm_target) <span class="hljs-keyword">and</span> os.listdir(rm_target):  <span class="hljs-comment"># 若为非空目录</span><br>            file_list = os.listdir(rm_target)  <span class="hljs-comment"># 继续先删深处的文件</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> file_list:<br>                self.do_rm(command + <span class="hljs-string">&#x27;/&#x27;</span> + i)<br>            os.rmdir(rm_target)  <span class="hljs-comment"># 最后再删掉当前这个已经空了的目录</span><br>        <span class="hljs-keyword">elif</span> os.path.isdir(rm_target) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> os.listdir(rm_target):  <span class="hljs-comment"># 空目录</span><br>            os.rmdir(rm_target)<br>        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># 普通文件</span><br>            os.remove(rm_target)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">puts_file</span>(<span class="hljs-params">self</span>):<br>        data = self.train_recv()<br>        file = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;f[复件]&#x27;</span>, mode=<span class="hljs-string">&#x27;wb&#x27;</span>)<br>        file.write(data)<br>        file.close()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">gets_file</span>(<span class="hljs-params">self, command</span>):<br>        file_name = command.split()[<span class="hljs-number">1</span>]<br>        my_file = <span class="hljs-built_in">open</span>(file_name, mode=<span class="hljs-string">&#x27;rb&#x27;</span>)  <span class="hljs-comment"># 字节流形式打开二进制文件</span><br>        data = my_file.read()<br>        self.train_send(data)<br>        my_file.close()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    s = Server(<span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">2000</span>)<br>    s.tcp_init()<br>    s.task()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>epoll多路复用</title>
    <link href="/2024/08/22/3.epoll%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"/>
    <url>/2024/08/22/3.epoll%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<font size=3><p>为了实现及时聊天，即两方可以任意向对方发送连续的多条消息的功能，需要使用epoll。在内核中，socket对象缓冲区recv()、标准输入缓冲区input()都分配了一段内存，内存对应一个<strong>整型编号</strong>（数组下标），这个编号就是<strong>文件描述符file describer</strong>。</p><span id="more"></span><p>我们创建epoll对象，注册要监控的fd和事件类型，让epoll去监控哪几个缓冲区发生了指定事件，以列表的形式主动报告给用户进程。</p><h1 id="1-使用epoll编写即时聊天"><a href="#1-使用epoll编写即时聊天" class="headerlink" title="1.使用epoll编写即时聊天"></a>1.使用epoll编写即时聊天</h1><details><summary>服务器代码</summary><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> socket<br><span class="hljs-keyword">import</span> select<br><span class="hljs-keyword">import</span> sys<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tcp_server</span>():<br>    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<br>    s_addr = (<span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">2000</span>)<br>    server.bind(s_addr)<br>    server.listen(<span class="hljs-number">128</span>)  <span class="hljs-comment"># 被动监听，激活端口</span><br>    new_client, new_client_addr = server.accept()<br>    <span class="hljs-built_in">print</span>(new_client_addr)<br>    epoll = select.epoll()  <span class="hljs-comment"># 创建一个epoll对象</span><br>    <span class="hljs-comment"># 注册要监控的缓冲区，发生指定事件向用户进程汇报</span><br>    epoll.register(new_client.fileno(), select.EPOLLIN)<br>    epoll.register(sys.stdin.fileno(), select.EPOLLIN)<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-comment"># 一直等只会在这里卡住，谁的缓冲区有数据，就填写到eventslist，列表里变存元组 (fd, 事件)</span><br>        events_list = epoll.poll(-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">for</span> fd,event <span class="hljs-keyword">in</span> events_list:<br>            <span class="hljs-keyword">if</span> fd == new_client.fileno():<br>                <span class="hljs-comment"># recv缓冲区有数据</span><br>                data = new_client.recv(<span class="hljs-number">100</span>).decode(<span class="hljs-string">&#x27;utf8&#x27;</span>)<br>                <span class="hljs-keyword">if</span> data:<br>                    <span class="hljs-built_in">print</span>(data)<br>                <span class="hljs-keyword">else</span>:<span class="hljs-comment"># 一旦对端断开，recv不会卡主，会返回空,内核会把client标记为一直可读</span><br>                    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;对方断开了&#x27;</span>)<br>                    <span class="hljs-keyword">return</span><br>            <span class="hljs-keyword">elif</span> fd == sys.stdin.fileno():<br>                <span class="hljs-comment"># input缓冲区有数据</span><br>                <span class="hljs-keyword">try</span>:  <span class="hljs-comment"># 按ctrl d让服务器断开</span><br>                    data = <span class="hljs-built_in">input</span>()<br>                <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>                    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;不想输入了，I want leave&#x27;</span>)<br>                    <span class="hljs-keyword">return</span><br>                new_client.send(data.encode(<span class="hljs-string">&#x27;utf8&#x27;</span>))<br>    server.close()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    tcp_server()<br><br></code></pre></td></tr></table></figure></details><p><img src="https://s2.loli.net/2024/08/22/XPfIjBzTDE5MmiH.png" alt="即时聊天测试结果"></p><h1 id="2-使用epoll实现聊天室"><a href="#2-使用epoll实现聊天室" class="headerlink" title="2.使用epoll实现聊天室"></a>2.使用epoll实现聊天室</h1><div class="note note-info">            <p>实现多人聊天，</p><ol><li>新增客户端断开后可以再次连接，服务器端不会退出（epoll解除绑定、关闭client对象）;</li><li>新建一个client列表，存储每个客户端对象，循环遍历查看缓冲区有无数据；</li><li>文件协议设计，聊天室增加用户名功能。</li></ol>          </div><p><img src="https://s2.loli.net/2024/08/23/UaLvRpJhrT8jtC9.png" alt="聊天室测试结果"></p><h1 id="3-持续发送多个文件，协议设计"><a href="#3-持续发送多个文件，协议设计" class="headerlink" title="3.持续发送多个文件，协议设计"></a>3.持续发送多个文件，协议设计</h1><div class="note note-warning">            <p>使用TCP连接发送文件时，首先要以<strong>字节流</strong>形式传送，如果持续发送多个文件，文件名1+文件1内容+文件名2+文件2内容+。。。存在<strong>粘包</strong>问题，两次发送的报文挨在一起，分不开。</p>          </div><p>我们采用<strong>开火车的方式</strong>解决粘包，如下所示。</p><ol><li>小火车</li></ol><ul><li>火车头填写长度：字节数，python需pack为4字节整型数</li><li>火车车厢填写内容：字符串字节流</li></ul><table><thead><tr><th align="center"></th><th align="center">文件名</th><th align="center">文件内容</th></tr></thead><tbody><tr><td align="center">车头</td><td align="center">文件名长度(4B)</td><td align="center">文件内容总长度(4B)</td></tr><tr><td align="center">车厢</td><td align="center">文件名</td><td align="center">文件内容</td></tr></tbody></table><p><strong>Python的struct模块</strong>，提供了一种机制，能将int、float等基本数据类型打包成字符串（实际上相当于其他语言的字节流），可以在网络上传输，而接收端也可以通过解包还原出初始的数据。</p><ul><li><p>pack(fmt, var1, var2,…)<br>按照给定的格式(fmt)，把数据封装成字符串(实际上类似于C结构体的字节流);</p></li><li><p>unpack(fmt, string)<br>按照给定的格式(fmt)解析字节流(string)，<strong>返回</strong>解析出来的<strong>tuple</strong>元组;</p></li><li><p>calcsize(fmt)<br>计算给定的格式(fmt)占用多少字节的内存</p></li><li><p><a href="https://blog.csdn.net/yzy1103203312/article/details/78238004">Python中的struct模块</a></p></li></ul><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><ul><li>写代码的时候对不确定的代码实现效果，<strong>自己动手写一个简单的例子</strong>验证一下就可以，这样就不至于代码写了一大堆，不确定错误在哪里。</li></ul><p><img src="https://s2.loli.net/2024/08/23/gY1eD3LfumUjVsb.png" alt=".png"></p></font>]]></content>
    
    
    
    <tags>
      
      <tag>socket</tag>
      
      <tag>epoll</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
